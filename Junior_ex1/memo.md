
# 目的
　1入力1出力の3層階層ニューラルネットワークを用いて関数近似を行う。

　与えられた学習データ、ここでは（入力、出力）の組を表現する関数を学習し、未知のパターンの入力に対する出力を近似関数によって求める。

# 理論
<dl>
    <dt>学習係数</dt>
        <dd>学習速度に影響</dd>
    <dt>慣性項係数</dt>
        <dd>前回の重みの変化量の影響度</dd>
</dl>

## ニューラルネットワーク
 + 全結合型ニューラルネットワークの概略図
 + Neuron 1つに注目した図を用いてNeuronの説明
 +

## 学習原理
　学習方法は慣性項を導入したバックプロパゲーション・アルゴリズムを使用。

　慣性項とは、学習を繰り返す上で前回の学習した変化量を使用した項のこと。

## 学習アルゴリズム
1. 順方向計算
2. ①の計算結果と教師データとの差異から各Neuronのパラメータを更新

### 更新式の導出
　次の計算結果と教師データとの二乗誤差を表す評価関数が最小になるように行われる。  
　評価関数は重みを引数にとる関数であるから、評価関数を最小にする重みを求める為には評価関数の重みについて偏微分したものを利用する。（二次関数の微分 = 接線の傾き だから、右上がり:wを小さく、右下がり:wを大きくする。図を用いて説明。)

 + 偏微分の計算
 + 更新式の表示

# 数値実験
 + まず、学習するデータセットの点プロットを表示する？
1. 前述の更新式に基づいてニューラルネットワークのプログラムを実装した。
2. 用意された学習データセット[]について学習を行い、得られた近似関数と評価関数の値を出力した。
    + パラメータ
         - 中間層の数：20
         - 学習係数：0.5
         - 慣性項係数：0.9
         - 全ての結合強度としきい値の初期値：0.5
3. ②において、全ての結合強度としきい値の初期値をランダムに設定し、同様にして学習を行った。


# 結果

1. 初期値を0.5にした時の結果
    + 初期状態の評価関数の値
    + 1回学習後の評価関数の値
    + 30000回学習後の評価関数の値
    + 得られた近似関数のグラフ（正解グラフと重ねて表示）
2. 初期値をランダムにした時の結果
    + 初期状態の評価関数の値
    + 1回学習後の評価関数の値
    + 30000回学習後の評価関数の値
    + 得られた近似関数のグラフ（正解グラフと重ねて表示）

# 結論
 + 与えられた学習データセットから関数近似を行うことができた。
 + それぞれの結合強度および、しきい値の初期値はランダムにしたほうが近似精度が高くなることが分かった。
 <!-- + 実装した1入力1出力ニューラルネットワークのプログラムは正しく動作した。 -->

　以上で課題1の実験は終了である。
